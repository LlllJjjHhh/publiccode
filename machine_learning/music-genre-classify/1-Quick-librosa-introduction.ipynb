{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ff6466",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- https://musicinformationretrieval.com/\n",
    "- https://towardsdatascience.com/music-genre-classification-with-python-c714d032f0d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4219b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b021c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la royalty-free-music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96330410",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'royalty-free-music/bensound-dubstep.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_array , sample_rate = librosa.load(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f93ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(music_array), type(sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_array.shape, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29088e4a",
   "metadata": {},
   "source": [
    "### Note:  The above selected  audio time series as a numpy array with a default sampling rate(sr) of 22KHZ mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_array2 , sample_rate2 = librosa.load(audio_path, sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc94fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_array2.shape, sample_rate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_array3 , sample_rate_none = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669be8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_array3.shape, sample_rate_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec41e8",
   "metadata": {},
   "source": [
    "## What is Sample Rate:\n",
    "- The sample rate is the number of samples carried by the selected audio per second, measured either in Hz or kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dfd439",
   "metadata": {},
   "source": [
    "# Playing audio in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c632e1",
   "metadata": {},
   "source": [
    "# Audio Signals or Waveform visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43296bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4), facecolor=(.9, .9, .9))\n",
    "librosa.display.waveshow(music_array2, sr=sample_rate2, color='pink')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37fcac9",
   "metadata": {},
   "source": [
    "# Spectrogram Visualization\n",
    "- A spectrogram is a visual representation of the spectrum of frequencies of sound or other signals as they vary with time. \n",
    "- Spectrograms are sometimes called sonographs, voiceprints, or voicegrams. \n",
    "- When the data is represented in a 3D plot, they may be called waterfalls. \n",
    "- In 2-dimensional arrays, the first axis is frequency while the second axis is time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117645c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(music_array2)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be422d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sample_rate2, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf086fa",
   "metadata": {},
   "source": [
    "## The graph \n",
    "- The vertical axis shows frequencies (from 0 to 10kHz), and the horizontal axis shows the time of the clip. \n",
    "- Since all action is taking place at the bottom of the spectrum, we can convert the frequency axis to a logarithmic one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11084545",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(music_array2.shape, sample_rate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(Xdb, sr=sample_rate2, x_axis='time', y_axis='log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4753e",
   "metadata": {},
   "source": [
    "# Run the default beat tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06576d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=music_array2, sr=sample_rate2)\n",
    "print('Estimated tempo: {:.2f} beats per minute'.format(tempo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4a571e",
   "metadata": {},
   "source": [
    "## Frames:\n",
    "- Frames here correspond to short windows of the signal (y), each separated by hop_length = 512 samples. \n",
    "- librosa uses centered frames, so that the kth frame is centered around sample k * hop_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00300444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert the frame indices of beat events into timestamps\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sample_rate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628099c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got help from here - https://musicinformationretrieval.com/beat_tracking.html\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(music_array2, alpha=0.1)\n",
    "plt.vlines(beat_times, -1, 1, color='r')\n",
    "plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f638c38",
   "metadata": {},
   "source": [
    "# Saving to the local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd608c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('temp_file_x.wav', x, samplerate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243089a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('temp_file_48000.wav', x, 48000, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce38c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_x, temp_sr = sf.read('temp_file_48000.wav')\n",
    "print(temp_x.shape, temp_sr)\n",
    "ipd.Audio(temp_x, rate=temp_sr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939446b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
